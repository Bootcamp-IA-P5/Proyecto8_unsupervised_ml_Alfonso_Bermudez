# ğŸ„ Taller de Aprendizaje AutomÃ¡tico No Supervisado (Mushrooms Dataset)
**Autor:** Alfonso BermÃºdez  
**Bootcamp IA â€“ Proyecto Individual**

---

### ğŸ“˜ DescripciÃ³n

Este repositorio contiene un taller prÃ¡ctico de **aprendizaje automÃ¡tico no supervisado**, usando tÃ©cnicas de **PCA** y **K-Means Clustering**, junto con una comparativa con un modelo supervisado (**Random Forest** optimizado con GridSearchCV).

El objetivo es analizar si los hongos pueden clasificarse como **comestibles o venenosos** en funciÃ³n de sus caracterÃ­sticas morfolÃ³gicas.

---

## ğŸ“‚ Dataset

Puedes obtener el dataset desde el siguiente enlace:

ğŸ”— [Mushroom Dataset - UCI Repository](https://archive.ics.uci.edu/ml/datasets/Mushroom)

- **Instancia:** Cada fila representa un hongo.
- **Variables:** Todas son **categÃ³ricas** (forma, color, olor, etc.).
- **Variable objetivo (`class`)**: Binaria â€” `e` (edible/comestible) o `p` (poisonous/venenoso).

---

## ğŸ§  Objetivos del taller

- Cargar y explorar un dataset categÃ³rico complejo.
- Tratar valores nulos y eliminar columnas no informativas.
- Codificar variables categÃ³ricas usando **One-Hot Encoding**.
- Reducir dimensionalidad con **PCA (AnÃ¡lisis de Componentes Principales)**.
- Aplicar **K-Means Clustering** para detectar estructuras ocultas en los datos.
- Comparar el rendimiento del modelo no supervisado con un modelo supervisado (**Random Forest**).

---

### ğŸ“‚ Estructura del proyecto

```
Proyecto8_unsupervised_ml_Alfonso_Bermudez/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA_unsupervised_ml_mushrooms.ipynb
â”œâ”€â”€ data/
â”œâ”€â”€ docs/
â”œâ”€â”€ src/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ TecnologÃ­as utilizadas

- Python 3.13.9  
- Pandas / NumPy
- Seaborn / Matplotlib
- Scikit-learn (`PCA`, `KMeans`, `RandomForestClassifier`, `GridSearchCV`)
- JupyterLab

---

## ğŸ—‚ï¸ Contenido del notebook

### 1. ğŸ“¥ Carga y exploraciÃ³n de datos
- VisualizaciÃ³n general del dataset.
- Conteo de valores nulos y valores Ãºnicos por variable.
- EliminaciÃ³n de columnas constantes o poco informativas.

### 2. ğŸ§¼ Preprocesamiento
- ImputaciÃ³n o eliminaciÃ³n de valores faltantes.
- ConversiÃ³n de variables categÃ³ricas con **OneHotEncoder**.
- SeparaciÃ³n entre `X` (features) e `y` (class).

### 3. ğŸ§ª PCA (AnÃ¡lisis de Componentes Principales)
- ReducciÃ³n de dimensionalidad a 2 componentes.
- VisualizaciÃ³n de los datos en 2D.
- EvaluaciÃ³n visual de separabilidad.

### 4. ğŸŒ³ ClasificaciÃ³n supervisada (Random Forest)
- Entrenamiento de un modelo de clasificaciÃ³n.
- EvaluaciÃ³n con mÃ©tricas de precisiÃ³n.
- Estudio del impacto del nÃºmero de componentes en el rendimiento del modelo.

### 5. ğŸ” Clustering con K-Means
- DeterminaciÃ³n del nÃºmero Ã³ptimo de clusters (mÃ©todo del codo).
- Entrenamiento y visualizaciÃ³n de clusters.
- EvaluaciÃ³n de la correspondencia entre clusters y clases reales (sin usar las etiquetas).

### ğŸ“Š Resultados obtenidos

  **Supervisado** `Random Forest`:  **Accuracy: $\approx 1.0000$** El problema es trivialmente clasificable con etiquetas. |
| **No Supervisado** `K-Means`:  **ARI: $\approx 0.99 - 1.00$** Coincidencia casi perfecta con las clases reales. |
| **ReducciÃ³n** `PCA (2D)`: Separa las clases de forma visible. La informaciÃ³n crucial se concentra eficientemente. |



### ğŸ¯ Conclusiones

- **KMeans (no supervisado)** logrÃ³ â‰ˆ **90% de precisiÃ³n** agrupando hongos **sin saber** si eran comestibles o venenosos.

- **Random Forest (supervisado)** logrÃ³ **100%** porque **sÃ­ sabÃ­a** las respuestas correctas durante el entrenamiento.

Cuando tenemos datos etiquetados (supervisado), podemos alcanzar mejores resultados, pero el no supervisado es increÃ­blemente Ãºtil cuando **no tenemos etiquetas** o queremos **descubrir grupos** que no conocÃ­amos.

