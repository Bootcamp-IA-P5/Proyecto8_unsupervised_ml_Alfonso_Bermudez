# ğŸ„ Taller de Aprendizaje AutomÃ¡tico No Supervisado (Mushrooms Dataset)
**Autor:** Alfonso BermÃºdez  
**Bootcamp IA â€“ Proyecto Individual**

---

## ğŸ“˜ DescripciÃ³n

Este repositorio contiene un taller prÃ¡ctico de **aprendizaje automÃ¡tico no supervisado**, usando tÃ©cnicas de **PCA** y **K-Means Clustering**, junto con una comparativa con un modelo supervisado (**Random Forest** optimizado con GridSearchCV).

Este proyecto explora el clÃ¡sico **dataset de hongos (Mushroom Dataset)** del repositorio UCI para analizar si las especies pueden clasificarse como **comestibles o venenosas** en funciÃ³n de sus caracterÃ­sticas morfolÃ³gicas.  

---

## ğŸ“‚ Dataset

Puedes obtener el dataset desde el siguiente enlace:

ğŸ”— [Mushroom Dataset - UCI Repository](https://archive.ics.uci.edu/ml/datasets/Mushroom)

- **Instancia:** Cada fila representa un hongo.  
- **Variables:** Todas son **categÃ³ricas** (forma, color, olor, tipo de anillo, etc.).  
- **Variable objetivo (`class`)**: Binaria â€” `e` (edible/comestible) o `p` (poisonous/venenoso).  
- Se detectaron valores faltantes en la variable `stalk-root`, imputados con la **moda**.

---

## ğŸ§  Objetivos del taller

- Explorar y limpiar un dataset categÃ³rico con valores faltantes.  
- Aplicar **One-Hot Encoding** para variables categÃ³ricas.  
- Reducir la dimensionalidad con **PCA (AnÃ¡lisis de Componentes Principales)**.  
- Identificar patrones ocultos mediante **K-Means** y **t-SNE**.  
- Comparar resultados con un modelo **supervisado (Random Forest)** optimizado con **GridSearchCV**.

---

## âš™ï¸ Pipeline metodolÃ³gico

1. **EDA (Exploratory Data Analysis)**  
   - IdentificaciÃ³n de valores nulos (`?`) en `stalk-root`.  
   - ImputaciÃ³n por moda (manteniendo el tamaÃ±o y balance del dataset).  
   - EliminaciÃ³n de columnas no informativas (`veil-type`).

2. **Preprocesamiento**  
   - ConversiÃ³n a formato numÃ©rico mediante *One-Hot Encoding*.  
   - Escalado de variables con `StandardScaler`.

3. **PCA (ReducciÃ³n de dimensionalidad)**  
   - Se conservaron las dos primeras componentes principales (PC1 y PC2),  
     que explican el **16.5 %** de la varianza total.  
   - Permite visualizar una separaciÃ³n parcial entre las dos clases.

4. **Clustering (No supervisado)**  
   - El **mÃ©todo del codo** sugiere *k â‰ˆ 4-5*, mientras que el **coeficiente silhouette** apunta a *k â‰ˆ 9-10*.  
   - Forzando *k = 2*, se obtiene una **coincidencia del 89 %** con las clases reales.  
   - Esto confirma que el dataset presenta una estructura separable, aunque no perfectamente lineal.  
   - El **t-SNE** refuerza esta conclusiÃ³n mostrando dos grupos principales con ligeros solapamientos.

5. **ClasificaciÃ³n supervisada (Random Forest)**  
   - Entrenamiento y optimizaciÃ³n con **GridSearchCV**.  
   - PrecisiÃ³n en test: **â‰ˆ 100 %**.  
   - Las variables mÃ¡s influyentes:  
     - `odor` (olor) â†’ casi determinante.  
     - `spore-print-color` (color de esporas).  
     - `ring-type` y `gill-size` (caracterÃ­sticas estructurales).

---

## ğŸ§© Resultados y anÃ¡lisis comparativo

Durante el anÃ¡lisis se observaron distintos comportamientos segÃºn la tÃ©cnica aplicada.  
El resumen siguiente refleja tanto los **resultados obtenidos** como las **decisiones razonadas** en cada fase:

| MÃ©todo | Tipo | MÃ©trica / Resultado | Observaciones |
|:--|:--|:--|:--|
| **PCA (2D)** | ReducciÃ³n | Varianza total explicada: **16.5 %** | Las dos primeras componentes principales (PC1, PC2) permiten visualizar cierta separaciÃ³n entre *comestibles* y *venenosos*, aunque con solapamientos. |
| **K-Means (Exploratorio)** | No supervisado | MÃ©todo del codo â†’ **k â‰ˆ 4â€“5**  | La inercia se estabiliza a partir de k=4â€“5, indicando que podrÃ­an existir subgrupos dentro de las clases principales. |
| **Coeficiente Silhouette** | No supervisado | MÃ¡x. en **k = 9**, valor medio **â‰ˆ 0.21** | Sugiere una estructura interna algo mÃ¡s compleja y difusa; los clusters no son totalmente compactos. |
| **K-Means (Forzado k=2)** | No supervisado | Accuracy â‰ˆ **89 %** respecto a las clases reales | Se observa una buena correspondencia con las etiquetas (*edible / poisonous*), aunque con cierto solapamiento. |
| **t-SNE** | No supervisado | VisualizaciÃ³n 2D no lineal | Refuerza la existencia de dos grupos principales con fronteras poco definidas. |
| **Random Forest (GridSearchCV)** | Supervisado | Accuracy â‰ˆ **99.9 %** | ClasificaciÃ³n prÃ¡cticamente perfecta al usar las etiquetas reales. |

---

## ğŸ” InterpretaciÃ³n global y conclusiones

- El **PCA** mostrÃ³ que las dos primeras componentes solo explican el **16.5 %** de la varianza,  
  lo cual es esperable en datasets categÃ³ricos con muchas variables codificadas.  
  Aun asÃ­, permitiÃ³ identificar una **separaciÃ³n parcial** entre las clases.
- El **K-Means** revelÃ³ una estructura interna **no perfectamente binaria**, con posibles **subgrupos naturales** dentro de las clases *edible* y *poisonous* (k â‰ˆ 4â€“5).  
  Esto puede deberse a combinaciones especÃ­ficas de variables como *odor*, *color de esporas* o *hÃ¡bitat*.
- Al **forzar k=2**, los clusters se alinearon en un **89 %** con las etiquetas reales,  
  lo que confirma una **separaciÃ³n latente**, aunque con zonas de intersecciÃ³n.
- El **coeficiente silhouette** relativamente bajo (â‰ˆ 0.21) sugiere que los lÃ­mites entre grupos son difusos,  
  probablemente por la alta dimensionalidad y el solapamiento entre caracterÃ­sticas visuales.
- El modelo **Random Forest**, en cambio, logrÃ³ una precisiÃ³n **casi perfecta (~100%)**,  
  lo que confirma que el conjunto de variables â€”especialmente `odor`, `spore-print-color` y `ring-type`â€”  
  contienen suficiente informaciÃ³n para discriminar las clases con exactitud.

> ğŸ§  En resumen:
> - Los mÃ©todos **no supervisados** evidencian patrones coherentes, pero imperfectos.  
> - El modelo **supervisado** aprovecha esa estructura subyacente para lograr una clasificaciÃ³n exacta.  
> - Este contraste refuerza la importancia de combinar **anÃ¡lisis exploratorio** con **modelos predictivos**,  
>   para comprender tanto la estructura como el comportamiento de los datos.

---

## ğŸ§° TecnologÃ­as utilizadas

- Python 3.13  
- Pandas / NumPy  
- Seaborn / Matplotlib  
- Scikit-learn (`PCA`, `KMeans`, `RandomForestClassifier`, `GridSearchCV`, `t-SNE`)  
- JupyterLab  

---

## ğŸ“ Estructura del proyecto

```
Proyecto8_unsupervised_ml_Alfonso_Bermudez/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA_unsupervised_ml_mushrooms.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€agaricus-lepiota.data     <-- dataset origial de UCI (no subido al repositorio)
â”œâ”€â”€ docs/
â”œâ”€â”€ src/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```