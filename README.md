# ğŸ„ Taller de Aprendizaje AutomÃ¡tico No Supervisado (Mushrooms Dataset)
**Autor:** Alfonso BermÃºdez  
**Bootcamp IA â€“ Proyecto Individual**

---

## ğŸ“˜ DescripciÃ³n

Este repositorio contiene un taller prÃ¡ctico de **aprendizaje automÃ¡tico no supervisado**, usando tÃ©cnicas de **PCA** y **K-Means Clustering**, junto con una comparativa con un modelo supervisado (**Random Forest** optimizado con GridSearchCV).

Este proyecto explora el clÃ¡sico **dataset de hongos (Mushroom Dataset)** del repositorio UCI para analizar si las especies pueden clasificarse como **comestibles o venenosas** en funciÃ³n de sus caracterÃ­sticas morfolÃ³gicas.  

---

## ğŸ“‚ Dataset

Puedes obtener el dataset desde el siguiente enlace:

ğŸ”— [Mushroom Dataset - UCI Repository](https://archive.ics.uci.edu/ml/datasets/Mushroom)

- **Instancia:** Cada fila representa un hongo.  
- **Variables:** Todas son **categÃ³ricas** (forma, color, olor, tipo de anillo, etc.).  
- **Variable objetivo (`class`)**: Binaria â€” `e` (edible/comestible) o `p` (poisonous/venenoso).  
- Se detectaron valores faltantes en la variable `stalk-root`, imputados con la **moda**.

---

## ğŸ§  Objetivos del taller

- Explorar y limpiar un dataset categÃ³rico con valores faltantes.  
- Aplicar **One-Hot Encoding** para variables categÃ³ricas.  
- Reducir la dimensionalidad con **PCA (AnÃ¡lisis de Componentes Principales)**.  
- Identificar patrones ocultos mediante **K-Means** y **t-SNE**.  
- Comparar resultados con un modelo **supervisado (Random Forest)** optimizado con **GridSearchCV**.

---

## âš™ï¸ Pipeline metodolÃ³gico

1. **EDA (Exploratory Data Analysis)**  
   - IdentificaciÃ³n de valores nulos (`?`) en `stalk-root`.  
   - ImputaciÃ³n por moda (manteniendo el tamaÃ±o y balance del dataset).  
   - EliminaciÃ³n de columnas no informativas (`veil-type`).

2. **Preprocesamiento**  
   - ConversiÃ³n a formato numÃ©rico mediante *One-Hot Encoding*.  
   - Escalado de variables con `StandardScaler`.

3. **PCA (ReducciÃ³n de dimensionalidad)**  
   - Se conservaron las dos primeras componentes principales (PC1 y PC2),  
     que explican el **16.5 %** de la varianza total.  
   - Permite visualizar una separaciÃ³n parcial entre las dos clases.

4. **Clustering (No supervisado)**  
   - El **mÃ©todo del codo** sugiere *k â‰ˆ 4-5*, mientras que el **coeficiente silhouette** apunta a *k â‰ˆ 9-10*.  
   - Forzando *k = 2*, se obtiene una **coincidencia del 89 %** con las clases reales.  
   - Esto confirma que el dataset presenta una estructura separable, aunque no perfectamente lineal.  
   - El **t-SNE** refuerza esta conclusiÃ³n mostrando dos grupos principales con ligeros solapamientos.

5. **ClasificaciÃ³n supervisada (Random Forest)**  
   - Entrenamiento y optimizaciÃ³n con **GridSearchCV**.  
   - PrecisiÃ³n en test: **â‰ˆ 100 %**.  
   - Las variables mÃ¡s influyentes:  
     - `odor` (olor) â†’ casi determinante.  
     - `spore-print-color` (color de esporas).  
     - `ring-type` y `gill-size` (caracterÃ­sticas estructurales).

---

## ğŸ§© Resultados comparativos

| MÃ©todo | Tipo | MÃ©trica | Resultado | Observaciones |
|:--|:--|:--|:--:|:--|
| **PCA (2D)** | ReducciÃ³n | Varianza total explicada | 16.5 % | SeparaciÃ³n parcial entre clases. |
| **K-Means** | No supervisado | Accuracy (k = 2) | 0.892 | Detecta dos grupos con solapamientos leves. |
| **t-SNE** | No supervisado | VisualizaciÃ³n | â€” | Dos grupos visibles con fronteras difusas. |
| **Random Forest** | Supervisado | Accuracy | 0.999 | ClasificaciÃ³n perfecta gracias a etiquetas reales. |

---

## ğŸ” Conclusiones finales

- El conjunto **presenta una estructura naturalmente separable** en dos grandes grupos (comestibles y venenosos).  
- La variable **`odor`** tiene una capacidad predictiva excepcional: puede casi determinar la clase por sÃ­ sola.  
- **PCA** y **t-SNE** permiten observar esta separaciÃ³n desde la perspectiva no supervisada.  
- **K-Means** logra identificar grupos coherentes sin conocer las etiquetas (â‰ˆ 89 % de coincidencia).  
- **Random Forest**, al incorporar las etiquetas, alcanza una clasificaciÃ³n prÃ¡cticamente perfecta (**â‰ˆ 100 %**).  

> ğŸ”¹ **ConclusiÃ³n general:**  
> Los mÃ©todos no supervisados revelan patrones internos consistentes,  
> mientras que el modelo supervisado confirma y perfecciona esa estructura.  
> Ambos enfoques se complementan: **el no supervisado explora**,  
> **el supervisado predice** con precisiÃ³n.

---

## ğŸ§° TecnologÃ­as utilizadas

- Python 3.13  
- Pandas / NumPy  
- Seaborn / Matplotlib  
- Scikit-learn (`PCA`, `KMeans`, `RandomForestClassifier`, `GridSearchCV`, `t-SNE`)  
- JupyterLab  

---

## ğŸ“ Estructura del proyecto

```
Proyecto8_unsupervised_ml_Alfonso_Bermudez/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA_unsupervised_ml_mushrooms.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€agaricus-lepiota.data     <-- dataset origial de UCI (no subido al repositorio)
â”œâ”€â”€ docs/
â”œâ”€â”€ src/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```